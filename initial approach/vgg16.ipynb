{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c55f199e-724e-4a6d-8490-526496c038ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import models\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os, subprocess\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0f10d49-4b84-414c-8918-1f9c8d3d64f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./data\"\n",
    "dir_lst = os.listdir(data_dir)\n",
    "for dir in dir_lst:\n",
    "    dir_path = os.listdir(f\"./data/{dir}\")\n",
    "\n",
    "    for name in dir_path:\n",
    "        if name == \".ipynb_checkpoints\":\n",
    "            print(name)\n",
    "            os.rmdir(f\"./data/{dir}/{name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47bc6320-9ca4-4efa-a0d4-048f6b2ec4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_TRANSFORM = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((512,512), antialias = True),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5)),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8d9d142-6f1a-47db-9797-e6760740d7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgfolder = ImageFolder(root=\"./data/train\",\n",
    "                              transform=IMG_TRANSFORM,\n",
    "                              target_transform=None\n",
    "                             )\n",
    "\n",
    "test_imgfolder = ImageFolder(root=\"./data/test\",\n",
    "                              transform=IMG_TRANSFORM\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5029d92a-00bc-4a3d-b6f9-86008c8995aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.MAX_IMAGE_PIXELS = None\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_imgfolder,\n",
    "\t\t\t\t\t\t\t  batch_size = 32,\n",
    "                              num_workers=os.cpu_count(),\n",
    "                              shuffle=True,\n",
    "                              drop_last=True \n",
    "                             )\n",
    "\n",
    "test_dataloader = DataLoader(dataset=test_imgfolder,\n",
    "\t\t\t\t\t\t\t  batch_size = 32,\n",
    "                              num_workers=os.cpu_count(),\n",
    "                              shuffle=True,\n",
    "                              drop_last=True \n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0821fad3-540f-47ca-854f-9f5c7171d243",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qkrwnstj/anaconda3/envs/qkrwnstj/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/qkrwnstj/anaconda3/envs/qkrwnstj/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "pre_trained_model = models.vgg16(pretrained=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d924e92f-d7b4-4b67-b7cb-1ee80f879521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2215f198-4699-4aa3-b0de-63432a5a86d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=20, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_trained_model.classifier[6].out_features=20\n",
    "pre_trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22ac3976-a9b0-4fe2-934e-9ae687e7efed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "# model setting\n",
    "model = pre_trained_model\n",
    "\n",
    "EPOCH = 50\n",
    "LEARNING_RATE = 1e-3 \n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE, weight_decay = 0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "print(\"Using device: \",DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a800dca9-50eb-4c37-8994-6c04c28ae140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(class_output, label, criterion):\n",
    "    CE_loss = criterion(class_output, label)\n",
    "\n",
    "    return CE_loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f35887cb-ff53-4df6-934c-04ef6048e88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, optimizer, criterion, epoch):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    epoch_loss = []\n",
    "    for index, (img_data,labels) in enumerate(train_loader):\n",
    "        img_data, labels = img_data.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(img_data)\n",
    "        loss = loss_fn(outputs, labels, criterion)\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        \n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss.append(loss.item())\n",
    "        if index%100==0:\n",
    "            print(f'train loss : {np.mean(epoch_loss):>7f}, [epoch:{epoch}, iter:{index}]')\n",
    "            \n",
    "    accuracy = correct / total\n",
    "    print(f\"TRAIN ACCURACY : {(100*accuracy):>0.1f}% [{correct}/{total}]\")\n",
    "    return np.mean(epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "166bbec2-b81c-46cf-9586-7a0a468f3dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_loader, model, criterion, epoch):\n",
    "    model.eval()\n",
    "\n",
    "    epoch_loss = []\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for index, (img_data,labels) in enumerate(test_loader):\n",
    "            img_data, labels = img_data.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(img_data)\n",
    "    \n",
    "            loss = loss_fn(outputs, labels, criterion)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            \n",
    "            epoch_loss.append(loss.item())\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    \n",
    "    print(f\"TEST ACCURACY : {(100*accuracy):>0.1f}% [{correct}/{total}]\")\n",
    "    return np.mean(epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee5442db-aa3a-4554-a670-99f3b731dafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858b7500-0e83-47c8-aba7-f9e360ea25c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|                                       | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1 \n",
      "-------------------------\n",
      "train loss : 9.335195, [epoch:1, iter:0]\n",
      "train loss : 3.616809, [epoch:1, iter:100]\n",
      "train loss : 3.269554, [epoch:1, iter:200]\n",
      "train loss : 3.123299, [epoch:1, iter:300]\n",
      "train loss : 3.031203, [epoch:1, iter:400]\n",
      "train loss : 2.974612, [epoch:1, iter:500]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qkrwnstj/anaconda3/envs/qkrwnstj/lib/python3.9/site-packages/PIL/TiffImagePlugin.py:858: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss : 2.935123, [epoch:1, iter:600]\n",
      "train loss : 2.904851, [epoch:1, iter:700]\n",
      "train loss : 2.876264, [epoch:1, iter:800]\n",
      "train loss : 2.859765, [epoch:1, iter:900]\n",
      "train loss : 2.838943, [epoch:1, iter:1000]\n",
      "train loss : 2.824859, [epoch:1, iter:1100]\n",
      "train loss : 2.809382, [epoch:1, iter:1200]\n",
      "train loss : 2.796275, [epoch:1, iter:1300]\n",
      "train loss : 2.785020, [epoch:1, iter:1400]\n",
      "train loss : 2.774746, [epoch:1, iter:1500]\n",
      "train loss : 2.764865, [epoch:1, iter:1600]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qkrwnstj/anaconda3/envs/qkrwnstj/lib/python3.9/site-packages/PIL/TiffImagePlugin.py:858: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss : 2.755371, [epoch:1, iter:1700]\n",
      "train loss : 2.748129, [epoch:1, iter:1800]\n",
      "train loss : 2.741427, [epoch:1, iter:1900]\n",
      "TRAIN ACCURACY : 16.0% [9879/61664]\n",
      "TEST ACCURACY : 18.7% [2179/11680]\n",
      "...MODEL SAVE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   2%|▌                         | 1/50 [27:09<22:10:50, 1629.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH:1 | train loss : 2.7387776316666024, test loss : 2.5965626644761595\n",
      "\n",
      "EPOCH 2 \n",
      "-------------------------\n",
      "train loss : 2.649712, [epoch:2, iter:0]\n",
      "train loss : 2.598808, [epoch:2, iter:100]\n",
      "train loss : 2.593772, [epoch:2, iter:200]\n",
      "train loss : 2.595323, [epoch:2, iter:300]\n",
      "train loss : 2.589351, [epoch:2, iter:400]\n",
      "train loss : 2.583602, [epoch:2, iter:500]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qkrwnstj/anaconda3/envs/qkrwnstj/lib/python3.9/site-packages/PIL/TiffImagePlugin.py:858: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss : 2.575858, [epoch:2, iter:600]\n",
      "train loss : 2.572456, [epoch:2, iter:700]\n",
      "train loss : 2.572790, [epoch:2, iter:800]\n",
      "train loss : 2.567370, [epoch:2, iter:900]\n",
      "train loss : 2.563753, [epoch:2, iter:1000]\n",
      "train loss : 2.557678, [epoch:2, iter:1100]\n",
      "train loss : 2.555543, [epoch:2, iter:1200]\n",
      "train loss : 2.556446, [epoch:2, iter:1300]\n",
      "train loss : 2.552682, [epoch:2, iter:1400]\n",
      "train loss : 2.549940, [epoch:2, iter:1500]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qkrwnstj/anaconda3/envs/qkrwnstj/lib/python3.9/site-packages/PIL/TiffImagePlugin.py:858: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss : 2.547929, [epoch:2, iter:1600]\n",
      "train loss : 2.547897, [epoch:2, iter:1700]\n",
      "train loss : 2.545545, [epoch:2, iter:1800]\n",
      "train loss : 2.542919, [epoch:2, iter:1900]\n",
      "TRAIN ACCURACY : 20.2% [12478/61664]\n",
      "TEST ACCURACY : 16.7% [1956/11680]\n",
      "...MODEL SAVE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   4%|█                         | 2/50 [54:28<21:48:05, 1635.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH:2 | train loss : 2.541893950199054, test loss : 2.525979761881371\n",
      "\n",
      "EPOCH 3 \n",
      "-------------------------\n",
      "train loss : 2.290074, [epoch:3, iter:0]\n",
      "train loss : 2.477750, [epoch:3, iter:100]\n",
      "train loss : 2.486967, [epoch:3, iter:200]\n",
      "train loss : 2.490834, [epoch:3, iter:300]\n",
      "train loss : 2.496138, [epoch:3, iter:400]\n",
      "train loss : 2.490900, [epoch:3, iter:500]\n",
      "train loss : 2.489587, [epoch:3, iter:600]\n",
      "train loss : 2.485671, [epoch:3, iter:700]\n",
      "train loss : 2.483252, [epoch:3, iter:800]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qkrwnstj/anaconda3/envs/qkrwnstj/lib/python3.9/site-packages/PIL/TiffImagePlugin.py:858: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss : 2.485235, [epoch:3, iter:900]\n",
      "train loss : 2.484604, [epoch:3, iter:1000]\n",
      "train loss : 2.480889, [epoch:3, iter:1100]\n",
      "train loss : 2.481131, [epoch:3, iter:1200]\n",
      "train loss : 2.479177, [epoch:3, iter:1300]\n",
      "train loss : 2.476302, [epoch:3, iter:1400]\n",
      "train loss : 2.473942, [epoch:3, iter:1500]\n",
      "train loss : 2.475841, [epoch:3, iter:1600]\n",
      "train loss : 2.473823, [epoch:3, iter:1700]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qkrwnstj/anaconda3/envs/qkrwnstj/lib/python3.9/site-packages/PIL/TiffImagePlugin.py:858: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss : 2.473737, [epoch:3, iter:1800]\n",
      "train loss : 2.472976, [epoch:3, iter:1900]\n",
      "TRAIN ACCURACY : 22.7% [13983/61664]\n",
      "TEST ACCURACY : 17.8% [2079/11680]\n",
      "...MODEL SAVE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   6%|█▍                      | 3/50 [1:21:33<21:17:01, 1630.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH:3 | train loss : 2.4716905505779683, test loss : 2.513133588882342\n",
      "\n",
      "EPOCH 4 \n",
      "-------------------------\n",
      "train loss : 2.566462, [epoch:4, iter:0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qkrwnstj/anaconda3/envs/qkrwnstj/lib/python3.9/site-packages/PIL/TiffImagePlugin.py:858: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss : 2.473447, [epoch:4, iter:100]\n",
      "train loss : 2.472657, [epoch:4, iter:200]\n",
      "train loss : 2.460264, [epoch:4, iter:300]\n",
      "train loss : 2.453531, [epoch:4, iter:400]\n",
      "train loss : 2.453367, [epoch:4, iter:500]\n",
      "train loss : 2.453296, [epoch:4, iter:600]\n",
      "train loss : 2.452635, [epoch:4, iter:700]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qkrwnstj/anaconda3/envs/qkrwnstj/lib/python3.9/site-packages/PIL/TiffImagePlugin.py:858: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss : 2.450531, [epoch:4, iter:800]\n",
      "train loss : 2.452687, [epoch:4, iter:900]\n",
      "train loss : 2.451036, [epoch:4, iter:1000]\n",
      "train loss : 2.445256, [epoch:4, iter:1100]\n",
      "train loss : 2.444453, [epoch:4, iter:1200]\n",
      "train loss : 2.446622, [epoch:4, iter:1300]\n",
      "train loss : 2.447741, [epoch:4, iter:1400]\n",
      "train loss : 2.447864, [epoch:4, iter:1500]\n",
      "train loss : 2.447858, [epoch:4, iter:1600]\n",
      "train loss : 2.445645, [epoch:4, iter:1700]\n",
      "train loss : 2.447052, [epoch:4, iter:1800]\n",
      "train loss : 2.447453, [epoch:4, iter:1900]\n",
      "TRAIN ACCURACY : 23.3% [14386/61664]\n",
      "TEST ACCURACY : 19.4% [2267/11680]\n",
      "...MODEL SAVE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   8%|█▉                      | 4/50 [1:48:34<20:47:03, 1626.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH:4 | train loss : 2.4483495372901882, test loss : 2.504375258210587\n",
      "\n",
      "EPOCH 5 \n",
      "-------------------------\n",
      "train loss : 2.602230, [epoch:5, iter:0]\n",
      "train loss : 2.435166, [epoch:5, iter:100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qkrwnstj/anaconda3/envs/qkrwnstj/lib/python3.9/site-packages/PIL/TiffImagePlugin.py:858: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss : 2.421673, [epoch:5, iter:200]\n",
      "train loss : 2.432977, [epoch:5, iter:300]\n",
      "train loss : 2.438147, [epoch:5, iter:400]\n",
      "train loss : 2.434146, [epoch:5, iter:500]\n",
      "train loss : 2.440158, [epoch:5, iter:600]\n",
      "train loss : 2.441230, [epoch:5, iter:700]\n",
      "train loss : 2.439090, [epoch:5, iter:800]\n",
      "train loss : 2.438056, [epoch:5, iter:900]\n",
      "train loss : 2.440694, [epoch:5, iter:1000]\n",
      "train loss : 2.438369, [epoch:5, iter:1100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qkrwnstj/anaconda3/envs/qkrwnstj/lib/python3.9/site-packages/PIL/TiffImagePlugin.py:858: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss : 2.434948, [epoch:5, iter:1200]\n",
      "train loss : 2.436320, [epoch:5, iter:1300]\n",
      "train loss : 2.434322, [epoch:5, iter:1400]\n",
      "train loss : 2.435652, [epoch:5, iter:1500]\n",
      "train loss : 2.435426, [epoch:5, iter:1600]\n",
      "train loss : 2.436043, [epoch:5, iter:1700]\n",
      "train loss : 2.436678, [epoch:5, iter:1800]\n",
      "train loss : 2.437255, [epoch:5, iter:1900]\n",
      "TRAIN ACCURACY : 23.8% [14692/61664]\n",
      "TEST ACCURACY : 21.9% [2558/11680]\n",
      "...MODEL SAVE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  10%|██▍                     | 5/50 [2:15:16<20:13:18, 1617.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH:5 | train loss : 2.4370303459593097, test loss : 2.498797262531437\n",
      "\n",
      "EPOCH 6 \n",
      "-------------------------\n",
      "train loss : 2.285460, [epoch:6, iter:0]\n",
      "train loss : 2.426437, [epoch:6, iter:100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qkrwnstj/anaconda3/envs/qkrwnstj/lib/python3.9/site-packages/PIL/TiffImagePlugin.py:858: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss : 2.417673, [epoch:6, iter:200]\n",
      "train loss : 2.435453, [epoch:6, iter:300]\n",
      "train loss : 2.436734, [epoch:6, iter:400]\n",
      "train loss : 2.434243, [epoch:6, iter:500]\n",
      "train loss : 2.437068, [epoch:6, iter:600]\n",
      "train loss : 2.438974, [epoch:6, iter:700]\n",
      "train loss : 2.438088, [epoch:6, iter:800]\n",
      "train loss : 2.435297, [epoch:6, iter:900]\n",
      "train loss : 2.435025, [epoch:6, iter:1000]\n",
      "train loss : 2.432050, [epoch:6, iter:1100]\n",
      "train loss : 2.431620, [epoch:6, iter:1200]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qkrwnstj/anaconda3/envs/qkrwnstj/lib/python3.9/site-packages/PIL/TiffImagePlugin.py:858: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss : 2.431630, [epoch:6, iter:1300]\n",
      "train loss : 2.430251, [epoch:6, iter:1400]\n",
      "train loss : 2.426921, [epoch:6, iter:1500]\n",
      "train loss : 2.428697, [epoch:6, iter:1600]\n",
      "train loss : 2.427318, [epoch:6, iter:1700]\n",
      "train loss : 2.427418, [epoch:6, iter:1800]\n",
      "train loss : 2.426499, [epoch:6, iter:1900]\n",
      "TRAIN ACCURACY : 23.9% [14739/61664]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  12%|██▉                     | 6/50 [2:41:59<19:42:51, 1612.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST ACCURACY : 17.9% [2087/11680]\n",
      "\n",
      "EPOCH:6 | train loss : 2.427998814362594, test loss : 2.548241824319918\n",
      "\n",
      "EPOCH 7 \n",
      "-------------------------\n",
      "train loss : 2.447647, [epoch:7, iter:0]\n",
      "train loss : 2.434177, [epoch:7, iter:100]\n",
      "train loss : 2.429394, [epoch:7, iter:200]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qkrwnstj/anaconda3/envs/qkrwnstj/lib/python3.9/site-packages/PIL/TiffImagePlugin.py:858: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss : 2.413185, [epoch:7, iter:300]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qkrwnstj/anaconda3/envs/qkrwnstj/lib/python3.9/site-packages/PIL/TiffImagePlugin.py:858: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss : 2.422419, [epoch:7, iter:400]\n",
      "train loss : 2.419181, [epoch:7, iter:500]\n",
      "train loss : 2.417802, [epoch:7, iter:600]\n",
      "train loss : 2.416406, [epoch:7, iter:700]\n",
      "train loss : 2.417007, [epoch:7, iter:800]\n",
      "train loss : 2.417133, [epoch:7, iter:900]\n",
      "train loss : 2.414654, [epoch:7, iter:1000]\n",
      "train loss : 2.415371, [epoch:7, iter:1100]\n",
      "train loss : 2.417462, [epoch:7, iter:1200]\n",
      "train loss : 2.417953, [epoch:7, iter:1300]\n",
      "train loss : 2.420403, [epoch:7, iter:1400]\n",
      "train loss : 2.425523, [epoch:7, iter:1500]\n",
      "train loss : 2.426542, [epoch:7, iter:1600]\n",
      "train loss : 2.426111, [epoch:7, iter:1700]\n",
      "train loss : 2.425564, [epoch:7, iter:1800]\n",
      "train loss : 2.425829, [epoch:7, iter:1900]\n",
      "TRAIN ACCURACY : 24.1% [14857/61664]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  14%|███▎                    | 7/50 [3:08:39<19:12:54, 1608.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST ACCURACY : 18.3% [2137/11680]\n",
      "\n",
      "EPOCH:7 | train loss : 2.4253127123942075, test loss : 2.5023584133958163\n",
      "\n",
      "EPOCH 8 \n",
      "-------------------------\n",
      "train loss : 2.316508, [epoch:8, iter:0]\n",
      "train loss : 2.384916, [epoch:8, iter:100]\n",
      "train loss : 2.417537, [epoch:8, iter:200]\n",
      "train loss : 2.419526, [epoch:8, iter:300]\n",
      "train loss : 2.419771, [epoch:8, iter:400]\n",
      "train loss : 2.417613, [epoch:8, iter:500]\n",
      "train loss : 2.418323, [epoch:8, iter:600]\n",
      "train loss : 2.415319, [epoch:8, iter:700]\n",
      "train loss : 2.419961, [epoch:8, iter:800]\n",
      "train loss : 2.424488, [epoch:8, iter:900]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qkrwnstj/anaconda3/envs/qkrwnstj/lib/python3.9/site-packages/PIL/TiffImagePlugin.py:858: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss : 2.419894, [epoch:8, iter:1000]\n",
      "train loss : 2.420206, [epoch:8, iter:1100]\n",
      "train loss : 2.421542, [epoch:8, iter:1200]\n",
      "train loss : 2.421953, [epoch:8, iter:1300]\n",
      "train loss : 2.419054, [epoch:8, iter:1400]\n",
      "train loss : 2.419771, [epoch:8, iter:1500]\n",
      "train loss : 2.420249, [epoch:8, iter:1600]\n",
      "train loss : 2.419430, [epoch:8, iter:1700]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qkrwnstj/anaconda3/envs/qkrwnstj/lib/python3.9/site-packages/PIL/TiffImagePlugin.py:858: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss : 2.418988, [epoch:8, iter:1800]\n",
      "train loss : 2.418718, [epoch:8, iter:1900]\n",
      "TRAIN ACCURACY : 24.2% [14928/61664]\n",
      "TEST ACCURACY : 16.8% [1957/11680]\n",
      "...MODEL SAVE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  16%|███▊                    | 8/50 [3:35:44<18:49:35, 1613.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH:8 | train loss : 2.4184123341382695, test loss : 2.472295115092029\n",
      "\n",
      "EPOCH 9 \n",
      "-------------------------\n",
      "train loss : 2.796915, [epoch:9, iter:0]\n",
      "train loss : 2.396260, [epoch:9, iter:100]\n",
      "train loss : 2.397210, [epoch:9, iter:200]\n",
      "train loss : 2.399718, [epoch:9, iter:300]\n",
      "train loss : 2.399959, [epoch:9, iter:400]\n",
      "train loss : 2.397930, [epoch:9, iter:500]\n",
      "train loss : 2.404484, [epoch:9, iter:600]\n",
      "train loss : 2.407096, [epoch:9, iter:700]\n",
      "train loss : 2.406426, [epoch:9, iter:800]\n",
      "train loss : 2.406417, [epoch:9, iter:900]\n",
      "train loss : 2.409799, [epoch:9, iter:1000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qkrwnstj/anaconda3/envs/qkrwnstj/lib/python3.9/site-packages/PIL/TiffImagePlugin.py:858: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss : 2.412263, [epoch:9, iter:1100]\n",
      "train loss : 2.415342, [epoch:9, iter:1200]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qkrwnstj/anaconda3/envs/qkrwnstj/lib/python3.9/site-packages/PIL/TiffImagePlugin.py:858: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss : 2.417424, [epoch:9, iter:1300]\n",
      "train loss : 2.415938, [epoch:9, iter:1400]\n",
      "train loss : 2.415784, [epoch:9, iter:1500]\n"
     ]
    }
   ],
   "source": [
    "train_loss_lst, test_loss_lst = [], []\n",
    "\n",
    "model_version = 1\n",
    "\n",
    "\n",
    "test_best_loss = 100\n",
    "test_current_loss = 100\n",
    "early_stop_threshold = 5\n",
    "early_stop_trigger = 0\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "for i in tqdm(range(EPOCH), desc = 'Train'):\n",
    "    print(f\"EPOCH {i+1} \\n-------------------------\")\n",
    "    train_loss = train(train_dataloader, model, optimizer, criterion, i+1)\n",
    "    test_loss = test(test_dataloader, model, criterion, i+1)\n",
    "\n",
    "    train_loss_lst.append(train_loss)\n",
    "    test_loss_lst.append(test_loss)\n",
    "\n",
    "    if test_loss < test_best_loss :\n",
    "        print(\"...MODEL SAVE...\")\n",
    "        test_best_loss = test_loss \n",
    "        \n",
    "        if model_version == 0:\n",
    "            torch.save(model.state_dict(),'contrastive_model_for_style_weight_v2_without_target_style.pth')\n",
    "        else:\n",
    "            torch.save(model.state_dict(),'contrastive_model_for_style_weight_vgg.pth')\n",
    "        \n",
    "    if test_current_loss < test_loss:\n",
    "        early_stop_trigger += 1 \n",
    "    else:\n",
    "        early_stop_trigger = 0 \n",
    "    test_current_loss  = test_loss \n",
    "\n",
    "    print(f'\\nEPOCH:{i+1} | train loss : {train_loss}, test loss : {test_loss}\\n')\n",
    "    \n",
    "    if early_stop_trigger >= early_stop_threshold:\n",
    "        break\n",
    "        \n",
    "print(\"DONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da12b1f9-ee33-4e24-9983-47749d373c2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb57e56-33cf-454e-8697-013513763e4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26709857-15e0-4ede-862a-22fda793c382",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5c944c-41ba-4c1d-8355-c45ce9353491",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb22a7e-3405-4c50-8caa-2134613b3bff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba4c834-847f-4c42-9eb1-6cd8767a246c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c6b914-80f9-42de-9c6e-bcbac2b1ea47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca09cac-f5ea-4f44-a246-5048db70838a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574155d3-f051-4059-b3a3-c6116dcc67b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe2b489-a4ef-436b-9f24-a73c41adf5da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qkrwnstj",
   "language": "python",
   "name": "qkrwnstj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
